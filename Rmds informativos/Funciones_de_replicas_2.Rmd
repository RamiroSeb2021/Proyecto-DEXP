---
title: "App Diseño de experimentos"
author:
  - name: Juan Sebastian Ramirez Ayala
  - name: Diana Catalina Hernandez Rojas
  - name: Yan Carlos Guerra Moreno
date: "`r format(Sys.Date())`"
output:
  html_document:
    self_contained: true
    number_sections: false
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: True
      smooth_scroll: true
      align: "left"
#    df_print: !expr pander::pander
    theme: spacelab
    highlight: pygments
editor_options:
  chunk_output_type: inline
---

<!-- Referenciar el archivo CSS -->

<link rel="stylesheet" type="text/css" href="styles.css">

<!-- Referenciar el archivo JavaScript -->

```{=html}
<script src="script.js"></script>
```

```{r set_up,include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, comment = "")
library(dexp)

#knitr::opts_chunk$set(engine.opts=list(python=list(echo = FALSE, warning = FALSE, message = FALSE, comment = "")))
```

# Cálculo de tamaño muestral 

El cálculo del tamaño muestral es una etapa clave en el diseño experimental, ya que permite determinar cuántas réplicas son necesarias por tratamiento para garantizar que los resultados del estudio sean estadísticamente significativos y tengan suficiente potencia para detectar efectos relevantes. Dependiendo del enfoque adoptado, puede buscarse minimizar la varianza de un estimador, maximizar la eficiencia bajo restricciones presupuestarias o garantizar la detección de diferencias mínimas entre tratamientos con un nivel de confianza preestablecido. A continuación se presentan distintos métodos para la determinación del tamaño muestral, adaptados a escenarios con o sin costos variables por tratamiento, así como modelos con componentes de varianza y métodos basados en pruebas post-hoc.


##  Determinación del Tamaño de Muestra sin Costo Variable por Tratamiento  {.tabset .tabset-fade .tabset-pills}

### Teoría

Asumiendo que los costos por tratamiento ($c_i > 0$) son variables, bajo la restricción:

$$
\sum_{i=1}^t c_i r_i = C \quad \text{(Restricción presupuestaria)}
$$

y considerando que:

$$
Var(\text{MELI}(L)) = \sum_{i=1}^t \frac{\lambda_i^2 \sigma_i^2}{r_i} \quad \text{(Ecuación 5.25)}
$$

donde $L = \sum_{i=1}^t \lambda_i \mu_i$ y

$$
\text{MELI}(L) = \sum_{i=1}^t \lambda_i \bar{y}_i \quad \text{(Ecuación 5.26)}
$$

#### Minimización Lagrangiana

Para minimizar $Var(\text{MELI}(L))$ sujeto a la restricción presupuestaria, construimos el lagrangiano:

$$
Q = \sum_{i=1}^t \frac{\lambda_i^2 \sigma_i^2}{r_i} + \phi \left( \sum_{i=1}^t c_i r_i - C \right) \quad \text{(Ecuación 5.27)}
$$

Al resolver lo anterior, obtenemos:

$$
r_i = \frac{|\lambda_i| \sigma_i}{\sqrt{\phi c_i}} \quad \text{(Ecuación 5.28)}
$$

donde el multiplicador de Lagrange es:

$$
\phi = \frac{\left( \sum_{i=1}^t |\lambda_i| \sigma_i \sqrt{c_i} \right)^2}{C^2}
$$

**Recomendación:** Los coeficientes $\lambda_i$ deben expresarse como fracciones para simplificar el cálculo de $r_i$.

#### Asignación Proporcional (Ecuación 5.29)

Si en lugar de optimizar con costos, asignamos las observaciones de forma proporcional a las desviaciones estándar (con $n$ fijo):

$$
\tilde{r}_{i} = \frac{n \sigma_i}{\sum_{s=1}^t \sigma_s}; \quad i = 1, \dots, t \quad \text{(Ecuación 5.29)}
$$

**Interpretación:** Los tratamientos con mayor variabilidad ($\sigma_i$) reciben más réplicas.

### Ejemplo

Supongamos que un agricultor tiene los siguientes datos referentes
a la producción en toneladas por hectárea de cuatro variedades de caña de
azúcar:

```{r}
# Crear el data frame con los datos
datos <- data.frame(
  V1 = c(78.82, 86.80, 68.65, 77.76, 75.80),
  V2 = c(56.60, 63.82, 58.71, 70.59, 81.74),
  V3 = c(105.126, 112.940, 108.118, 121.105, 115.870),
  V4 = c(96.89, 90.91, 92.97, 97.98, 95.93)
)

# Calcular media y desviación estándar con redondeo como en la imagen
media <- c(76.7, 67.40, 109.100, 92.80)
desviacion <- c(6.27, 9.57, 12.0, 3.32)

# Añadir nombres de fila
rownames(datos) <- c("1", "2", "3", "4", "5")

# Añadir filas de media y desviación
datos["Media", ] <- media
datos["Desviación", ] <- desviacion

# Mostrar la tabla
DT::datatable(datos)
```

Se observa que hay una proporcionalidad en las desviaciones estándar, entonces por (5.29) los tamaños de muestra adecuados para cada variedad
serían:

$$
\tilde{r}_1=\frac{(5*4)*(6.27)}{6.27+ 9.57+ 12+ 3.32}= 4.0243\approx4
$$

$$
\tilde{r}_2=\frac{(5*4)*(9.57)}{6.27+ 9.57+ 12+ 3.32}= 6.1424\approx6
$$

$$
\tilde{r}_3=\frac{(5*4)*(12)}{6.27+ 9.57+ 12+ 3.32}= 7.7021\approx8
$$

$$
\tilde{r}_4=\frac{(5*4)*(3.32)}{6.27+ 9.57+ 12+ 3.32}= 2.1309\approx2
$$

Las réplicas asignadas por cada uno de los tratamientos son $4,6,8,2$ respectivamente.

## Determinación del Tamaño de Muestra con Costo Variable por Tratamiento {.tabset .tabset-fade .tabset-pills}

### Teoría

Asumiendo que los costos por tratamiento ($c_i > 0$) son variables, bajo la restricción:

$$
\sum_{i=1}^t c_i r_i = C \quad \text{(Restricción presupuestaria)}
$$

y considerando que:

$$
Var(\text{MELI}(L)) = \sum_{i=1}^t \frac{\lambda_i^2 \sigma_i^2}{r_i} \quad \text{(Ecuación 5.25)}
$$

donde $L = \sum_{i=1}^t \lambda_i \mu_i$ y

$$
\text{MELI}(L) = \sum_{i=1}^t \lambda_i \bar{y}_i \quad \text{(Ecuación 5.26)}
$$

#### Minimización Lagrangiana

Para minimizar $Var(\text{MELI}(L))$ sujeto a la restricción presupuestaria, construimos el lagrangiano:

$$
Q = \sum_{i=1}^t \frac{\lambda_i^2 \sigma_i^2}{r_i} + \phi \left( \sum_{i=1}^t c_i r_i - C \right) \quad \text{(Ecuación 5.27)}
$$

Al resolver lo anterior, obtenemos:

$$
r_i = \frac{|\lambda_i| \sigma_i}{\sqrt{\phi c_i}} \quad \text{(Ecuación 5.28)}
$$

donde el multiplicador de Lagrange es:

$$
\phi = \frac{\left( \sum_{i=1}^t |\lambda_i| \sigma_i \sqrt{c_i} \right)^2}{C^2}
$$

**Recomendación:** Los coeficientes $\lambda_i$ deben expresarse como fracciones para simplificar el cálculo de $r_i$.

### Ejemplo

Supongamos que un agricultor tiene los siguientes datos referentes
a la producción en toneladas por hectárea de cuatro variedades de caña de
azúcar y sus respectivos costos:

```{r}
library(DT)

# Datos principales
datos <- data.frame(
  V1 = c(78.82, 86.80, 68.65, 77.76, 75.80),
  V2 = c(56.60, 63.82, 58.71, 70.59, 81.74),
  V3 = c(105.126, 112.940, 108.118, 121.105, 115.870),
  V4 = c(96.89, 90.91, 92.97, 97.98, 95.93)
)

# Agregar filas
media <- c(76.7, 67.40, 109.100, 92.80)
desviacion <- c(6.27, 9.57, 12.0, 3.32)
costos <- c(1000, 200, 700, 1100)

rownames(datos) <- c("1", "2", "3", "4", "5")
datos["Media", ] <- media
datos["Desviación", ] <- desviacion
datos["Costos", ] <- costos

# Crear tabla del presupuesto como otro data.frame
presupuesto <- data.frame(
  Concepto = "Presupuesto total del experimento",
  Valor_COP = format(50000, big.mark = ".", decimal.mark = ",")
)

# Mostrar ambas tablas en pestañas
htmltools::tagList(
  DT::datatable(datos, caption = htmltools::tags$strong("Tabla de datos del experimento")),
  DT::datatable(presupuesto, caption = htmltools::tags$strong("Presupuesto"))
)
```

Se observa que hay tenemos un costo por cada tratamiento y un presupuesto total, entonces por (5.28) los tamaños de muestra adecuados para cada variedad serían:

Iniciando por el calculo de $\Phi$

$$
\Phi= \sqrt{\frac{\left(\left(\frac{1}{4}*6.27*\sqrt{1000}\right)+\left(\frac{1}{4}*9.57*\sqrt{200}\right)+\left(\frac{1}{4}*12*\sqrt{700}\right)+\left(\frac{1}{4}*3.32*\sqrt{1100}\right)\right)^2}{50000^2}}=1.448629\times10^{-05}
$$

$$
r_1=\frac{\frac{1}{4}*6.27}{\sqrt{1.448629\times10^{-05}*1000}}=13.0235\approx13
$$

$$
r_2=\frac{\frac{1}{4}*9.57}{\sqrt{1.448629\times10^{-05}*200}}=44.4486\approx44
$$

$$
r_3=\frac{\frac{1}{4}*12}{\sqrt{1.448629\times10^{-05}*700}}=29.7915\approx30
$$

$$
r_4=\frac{\frac{1}{4}*3.32}{\sqrt{1.448629\times10^{-05}*1100}}=6.5751\approx7
$$

Las réplicas asignadas por cada uno de los tratamientos son $13,44,30,7$ respectivamente.

## Asignación de tratamientos y réplicas con Función de Costos y Varianza Máxima {.tabset .tabset-fade .tabset-pills}

### Teoría

En el modelo de componentes de varianza tanto el número de tratamientos $t$ como el número de réplicas $r$ son variables y sus estimaciones están ligadas con el control de dichas varianzas. Un criterio usual para elegir los valores de $r$ y $t$ es el de minimizar los costos en la estimación de la media $\mu$. Una medida de la cantidad de información disponible para estimar $\mu$ es la varianza de la media muestral dada por:

$$
v(\bar{y}..) = \frac{\sigma^2}{rt} + \frac{\sigma_A^2}{t}
$$

En el caso de un diseño C.A. (Completamente Aleatorizado).

El problema se reduce a encontrar los valores de $r$ y $t$ que minimicen la función de costos dada por:

$$
C = C_1 t + C_2 t r
$$

para una varianza $v(\bar{y}..)$ fija, donde $C_1$ es el costo por unidad de tratamiento y $C_2$ es el costo por unidad experimental. La solución matemática es, según Mendenhall (1968):

$$
t = \frac{1}{v(\bar{y}..)} \left( \hat{\sigma}_A^2 + \sqrt{\frac{\hat{\sigma}_A^2\hat\sigma^2C^2}{C^1}}  \right)
$$

y

$$
r = \sqrt{\frac{\hat\sigma^2 C_1}{\hat{\sigma}_A^2 C_2}}
$$

### Ejemplo

Un estudio genético en ganado, consistió en seleccionar aleatoriamente varios machos (toros) apareados con grupos separados de hembras. Cuando nacieron los terneros, se midieron los pesos iniciales como
medida en un estudio de pesos hereditarios (estudios de progene). En la tabla a continuación se presentan los pesos al nacer de los terneros de cada uno de cinco grupos de apareamiento.

```{r}
# Crear el data frame
datos <- data.frame(
  `Macho_número_85` = c(61, 71, 56, 75, 99, 80, 75, 62),
  `Macho_número_113` = c(75, 102, 95, 103, 98, 115, NA, NA),
  `Macho_número_134` = c(58, 60, 59, 65, 54, 57, NA, NA),
  `Macho_número_158` = c(57, 121, 56, 58, 101, 110, 67, NA),
  `Macho_número_165` = c(59, 46, 120, 115, 93, 105, 75, 115)
)

# Mostrar la tabla
DT::datatable(datos)
```

Obteniendo la tabla ANOVA

```{r}
# Crear los datos en formato largo
replicacion <- rep(1:8, times = 5)
toro <- rep(c(85, 113, 134, 158, 165), each = 8)
respuesta <- c(
  61, 71, 56, 75, 99, 80, 75, 62,  # Toro 85
  75, 102, 95, 103, 98, 115, NA, NA,  # Toro 113
  58, 60, 59, 65, 54, 57, NA, NA,  # Toro 134
  57, 121, 56, 58, 101, 110, 67, NA,  # Toro 158
  59, 46, 120, 115, 93, 105, 75, 115  # Toro 165
)

# Crear el data frame
datos <- data.frame(
  Toro = as.factor(toro),
  Respuesta = respuesta
)

# Eliminar filas con NA
datos <- na.omit(datos)

# ANOVA
modelo <- aov(Respuesta ~ Toro, data = datos)
summary(modelo)
```

De la anterior tabal pondemos obtener los valores de $\hat\sigma_e^2$ y de $\hat\sigma_A^2$

$$
\hat\sigma_e^2=\text{CME}=416.2
$$

$$
\hat\sigma_A^2=\frac{\text{CMA}-\text{CME}}{r_0}=\frac{(1517.6-416.2)}{6.97}=158.02
$$

Donde,

$$
r_0=\frac{\left(35-\frac{\left(8^2+6^2+6^2+7^2+8^2\right)}{35}\right)}{4}=6.97
$$

Suponiendo una varianza máxima $V(\bar{y}_{..})=43.49$, $C1 = 150000$ y $C2 = 50000$, se encuentra que:

$$
t = \frac{1}{43.49} \left( 158.015 + \sqrt{\frac{(158.015)(416.21409)(50000)}{150000}}  \right)=7.04
$$

y

$$
r = \sqrt{\frac{(416.21409) (150000)}{(158.015) (50000)}}=3.35
$$

Para una varianza de la media muestral no mayor de 43,49, deberían seleccionarse 7 toros y 3 terneros por cada toro, asumiendo que el costo experimental de cada toro es de $150000$ y el de cada ternero es de $50000$.

## Estimación S1 y df1 {.tabset .tabset-fade .tabset-pills}

### Teoría

Ocasionalmente el experimentador no define estimadores de varianza en la forma $S_1^2$, pero conoce “algo” acerca de los órdenes de magnitud para relacionar la información con los límites superior e inferior de la desviación estándar dentro de las cantidades máximas $S_1$ y $df_1$.

Harris, Horvitz & Mood (1948) proponen un procedimiento simple: Primero el experimentador se cuestiona por los límites inferior y superior ($S_I$, $S_S$) de la desviación estándar, suponiendo que él desea estimar 7\% y 12\% de la media para los límites superior e inferior, y la desviación estándar de la media es 30, entonces $S_I = (0{,}7)(30) = 2{,}1$ y $S_S = (0{,}12)(30) = 3{,}6$.

La estimación de la desviación estándar es el promedio de los dos estimadores:

$$
S_1 = \frac{S_I + S_S}{2} = 2{,}85
$$

Para obtener $df_1$ es necesario que el investigador tenga alguna “confianza” sobre los estimadores. Se calculan los valores de 
$\sqrt{\chi^2_{(0{,}1)} / \chi^2_{(0{,}9)}}$ para varios grados de libertad, el valor más cercano al cociente $S_S / S_I$ se considera como los grados de libertad asociados con $S_1$ ($df_1$). Para el ejemplo $S_S / S_I = 1{,}72$ y de la tabla 
$\sqrt{\chi^2_{(12;0{,}1)} / \chi^2_{(12;0{,}9)}} = 1{,}72$, de donde se asume que $S_1$ tiene asociados 12 grados de libertad, con este valor se estima $r$.


### Ejemplo 

En este caso usaremos la función `calcular_S1_df1` para hacer el cálculo del ejemplo anterior.

```{r, echo=TRUE}
library(dexp)
set.seed(123)
calcular_S1_df1(desviacion_estandar = 30, Si = 0.07, Ss = 0.12)
```




## Metodo de tukey {.tabset .tabset-fade .tabset-pills}

El método de Tukey para el cálculo del tamaño muestral de las réplicas por tratamiento tiene como objetivo asegurar que, al momento de realizar el diseño experimental, sea posible detectar una diferencia mínima significativa entre los tratamientos en la variable de interés al aplicar comparaciones pareadas mediante pruebas _post-hoc_.

En otras palabras, si al aplicar estas pruebas no se detecta una diferencia significativa, se debe a que la diferencia establecida previamente como mínima detectable no se logró identificar, lo que está directamente relacionado con el tamaño muestral calculado inicialmente.

Para aplicar esta prueba es necesario contar con información a priori sobre la varianza del error experimental. Si no se dispone de dicha información, y por lo tanto tampoco de los grados de libertad asociados, se procede a estimarla mediante la función `calcular_S1_df1()`. 

Parámetros:

### Teoría

Un intervalo de confianza de $(1 - \alpha) \cdot 100$ de longitud $\leq 2d$ para la diferencia de cualquier par de medias, cuando se tiene un conjunto de $t$ tratamientos, se obtiene a partir de la expresión del siguiente proceso:

Si hay $t$ medias (asociadas con los tratamientos), se hacen comparaciones dos a dos, es decir:

$$
\frac{\bar{Y}_{\max} - \bar{Y}_{\min}}{\sqrt{CME/r}} \sim q_{t;df_2}
$$

Sea $P_0 \leq P$ la longitud del intervalo que cubre todas las diferencias $\leq 2d$, entonces:

$$
P_0 = P\left(2S q_{1 - \alpha}/\sqrt{r} \leq 2d\right)
$$

donde $S = \sqrt{CME}$ y $q_{1 - \alpha}$ es el límite en la tabla A.12 del apéndice de rangos studentizados. Desde esta expresión se encuentra que:

$$
P_0 = P\left(S^2 \leq \frac{d^2 r}{q_{(1 - \alpha)}^2}\right)
$$

En esta expresión, al dividir por un $S^2$ previo, $S_1^2$, para obtener una $F$, se sigue:

$$
P_0 = P\left(\frac{S^2}{S_1^2} \leq \frac{d^2 r}{q_{(1 - \alpha)}^2 S_1^2}\right)
$$

Con $\frac{S^2}{S_1^2} \sim F(df_2, df_1)$, se obtiene finalmente:

$$
r = F_{(df_2, df_1; 1 - \alpha)} \cdot \frac{q^2_{t; df_2; 1 - \alpha/2}}{d^2}
$$

### Ejemplo

Retomando el ejemplo del libro 5.11, sea $S_1^2 = 141{,}6$, $df_1 = 40$ y $d = 20$.  
Los valores de $gl_E$ y $q_{t; df_2; 1 - \alpha}$ dependen del diseño y de los valores de $1 - \beta$.  
Si se supone $S_1$ como en el diseño completamente aleatorizado con $r = 6$, $1 - \beta = 0{,}9$ y $df_2 = 30$, entonces:

\[
\begin{align*}
gl(\text{Total}) &= 35, \\
gl(\text{Tratamientos}) &= 5, \\
gl(\text{Error}) &= 30.
\end{align*}
\]

Así, $F_{(30;40;0{,}10)} = 1{,}54$ y $q_{(5;30;0{,}10)} = 4{,}30$, donde $q$ corresponde al valor apropiado en la tabla A.12 de rangos studentizados.

Con estos resultados y de la ecuación (5.24), se obtiene:

$$
r = \frac{(141{,}6)(4{,}30)^2(1{,}54)}{400} = 10{,}08
$$

---

Para este caso, el estimador es sesgado. Si se desea garantizar que la longitud del intervalo sea $2A$, entonces de (5.18) se encuentra:

$$
r = \frac{2\sigma^2 t_{1-\alpha}^2 \Gamma^2\left( \frac{r}{2} \right)}{A^2 (r - 1) \Gamma^2\left( \frac{r - 1}{2} \right)}
$$

---

Como el valor de $df_2$ fue subestimado, se toma $r = 9$, entonces $df_2 = 48$,  
$q_{(5;48;0{,}90)} = 4{,}2$, $F_{(48;40;0{,}10)} = 1{,}48$ y $r = 9{,}2$.

Como el valor de $r > 9$, entonces con $r = 10$, va a ser lo suficientemente grande para esta propuesta,  
se puede obtener un intervalo de confianza con **10 réplicas** y el **95 % de confianza**, el cual es mayor que $2d$ en longitud en el 90 % de los experimentos.

Ahora vamos a usar la [librería](https://github.com/RamiroSeb2021/package-dexp) que creamos:

```{r, echo=TRUE}
library(dexp)
calcular_r_MT(
  T_ = 6,
  D = 20,
  ro = 6,
  S1 = sqrt(141.6),
  df1 = 40
)
```

El valor `r` representa el tamaño de réplica calculado mediante el **método de Tukey**, siendo `A` la diferencia mínima que se desea detectar con dicho tamaño. Por otro lado, `r_i` es el tamaño de réplica cuyo valor se aproxima más a lograr la diferencia mínima requerida, denominada `A_i`. Las listas `lista_r` y `valores_A` contienen valores de tamaño de réplica y las correspondientes diferencias mínimas detectables (`A`), calculadas tomando como referencia el valor de `r`.

Según el método de Tukey, se concluye que para detectar una diferencia mínima de 20 unidades se necesita un tamaño de réplica de 10. No obstante, esto implica que la diferencia real podría estar subestimada, por ejemplo, en un valor como 9.48. Esto puede interpretarse también como que, al emplear un tamaño de 10 réplicas, el contraste será más estricto para rechazar la hipótesis nula $H_0$. En cambio, utilizar el valor `r_i` proporciona un enfoque ligeramente más flexible, lo que puede facilitar la detección de la diferencia deseada con un balance adecuado entre error tipo I y tipo II.


## Número de réplicas en el modelo de efectos aleatorios 

El cálculo del número de réplicas en un diseño experimental con modelo de efectos aleatorios es fundamental cuando se desea asegurar una potencia estadística adecuada en pruebas ANOVA. En este contexto, el objetivo es determinar cuántas observaciones por tratamiento son necesarias para detectar diferencias significativas entre niveles de un factor aleatorio, considerando la variabilidad inherente del experimento.

Aunque la potencia de la prueba se basa en la distribución _F_, su determinación puede simplificarse mediante el uso de curvas características de operación (_OC curves_), que permiten visualizar la probabilidad de cometer errores tipo II ($\beta$) en función de diferentes configuraciones del diseño.

Este enfoque es especialmente útil en estudios donde los factores no son controlados directamente sino seleccionados aleatoriamente de una población más amplia (por ejemplo, lotes, sujetos, ubicaciones), y se requiere garantizar que el diseño tenga suficiente sensibilidad para detectar efectos reales entre tratamientos o unidades experimentales.

### Teoría

En el caso del ANOVA de una vía de clasificación:

$$
Y_{ij} = \mu + T_i + \varepsilon_{ij}
$$

- $\mu$: media general  
- $T_i$: efecto diferencial del tratamiento  
- $\varepsilon_{ij}$: error de la unidad observacional

Nosotros estimábamos a $T_i$ como si fuera un valor fijo, pero cuando tenemos efectos aleatorios:

$$
\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2_\varepsilon)
$$

Ahora $T_i$ va a ser aleatorio de individuo a individuo:

$$
T_j \sim \mathcal{N}(0, \sigma^2_T)
$$

Así tendremos dos efectos de varianza, entonces la idea se hace grande cuando vemos el diseño completamente al azar desde el punto de vista de los efectos aleatorios, ya no nos va a interesar evaluar la misma hipótesis.

**Hipótesis en efectos fijos:**

$$
H_0: \; T_1 = T_2 = \dots = T_K = 0
$$

Si no que:

**Hipótesis en efectos aleatorios:**

$$
H_0: \; \sigma^2_T = 0 \quad \text{(La varianza de los efectos aleatorios sea estadísticamente cero)}
$$

El cálculo es el mismo, solo que la hipótesis cambia.

> **Aclaración:**  
Que $T_k = 0 \Rightarrow \sigma^2_T = 0$, pero no al revés.  
Es decir, si $\sigma^2_T = 0$ implica que $T_k$ son iguales, pero no a cero.

**¿Cuándo decidimos usar cuál?**

En efectos fijos, los $T$ decimos que son parámetros fijos, que se espera que afecten a la variable dependiente de forma directa.  
En cambio, los efectos aleatorios me ayudan para explicar la variabilidad no explicada de las explicativas (punto de vista aleatorio).

**Ejemplo:**  
Si se tiene un estudio de diferentes fertilizantes y queremos evaluar el rendimiento en una cosecha, el investigador está pensando en elegir solo tres tipos de fertilizante.  
Para él, es un valor fijo dado que lo decidió bajo experiencia y quiere evaluar entre esos tres.  
→ **Efecto fijo**

Ahora, si en el mismo ejercicio se tiene un grupo más amplio de fertilizantes (20, 30, ..., X) y elijo aleatoriamente 3 por medio de un muestreo, entonces estoy pensando en efectos aleatorios.  
En ese caso, me interesa estimar la variabilidad del rendimiento de lo que estamos midiendo, causado por los diferentes tipos de fertilizantes.

Y en ese intento, la varianza asociada a los fertilizantes no se ve influenciada por la manera en que se eligen aleatoriamente los fertilizantes que se iban a usar en el estudio.

→ La diferencia de un modelo a otro reside en la concepción del experimento, pero en el contraste de las diferencias, o desde el punto de vista estadístico, es exactamente la misma tanto en efectos fijos como en efectos aleatorios.

Otra diferencia es que en E.F. a mí me interesa comparar niveles específicos, i.e., el fertilizante 1 vs. el 2, se comparan niveles específicos.

En cambio, en E.A. es controlar o evaluar qué tanto podrían cambiar la variabilidad en el rendimiento, o en la variable de respuesta por efecto del tratamiento.

→ Para contrastar el ejercicio se calcula el estadístico $F$ ya sea visto en E.F. o E.A.:

$$
F = \frac{CM_{Trat}}{CM_{Res}}
$$

Una cosa importante a tener en cuenta es que en el numerador de $F$ hay una combinación entre los $\sigma^2_T$ (variabilidad de tratamientos) y $\sigma^2_\varepsilon$ (variabilidad del error experimental).  
En cambio, en $CM_{Res}$ solo se tiene $\sigma^2_\varepsilon$.


→ Eso sería lo primero.

Ahora el ejercicio para calcular $CM_{Trat}$ para E.A. es el siguiente:

Suponemos que:

$$
SC_{Tot} = SC_{Trat} + SC_{Res}
$$

Sabemos que son chi-cuadrados, entonces:

$$
CM_{Trat} = \frac{SC_{Trat}}{K - 1} \sim \chi^2 \Rightarrow \mathbb{E}(CM_{Trat}) = \sigma^2_\varepsilon + r \cdot \sigma^2_T
$$

Donde $K$ es el número de tratamientos.  
Y para $CM_{Res}$:

$$
\mathbb{E}(CM_{Res}) = \sigma^2_\varepsilon
$$

Al final, va a pasar que la estadística $F$ bajo la hipótesis nula estará a tener distribución $F$, pero cuando no estoy bajo elsupuesto de la hipótesis nula, i.e., si $\sigma^2_T \neq 0$, el resultado de $F$ va a depender obligatoriamente de $\sigma^2_T$.

→ Las curvas características de operación (curvas OC) para el anterior escenario me dicen que a partir de la distribución exacta de la estadística $F$, cuando el $F$ no es centrado o no central, me dice que va a haber un cambio proporcional entre $F$ y $\sigma^2_T$.  
Entonces, lo que uno hace es una suerte de cociente:

$$
\rho = \frac{\sigma^2_T}{\sigma^2_\varepsilon}
$$

→ Para el ejercicio uno hace lo siguiente:

1. Simulación de cómo va a ser la potencia.  
   Hace el cálculo por el ANOVA:

   - Fijamos el número de tratamientos ($t$)  
   - Fijamos el número de réplicas ($r$)  
   - Fijamos $\sigma^2_\varepsilon$  
   - Fijamos $\beta$
   
Supongamos que ya tenemos claro el modelo:

$$
y_{ij} = \mu + T_j + \varepsilon_{ij}
$$

→ De $\sigma^2_\varepsilon$ y $\beta$ se puede recuperar $\sigma^2_T$.  
$T_j$ tiene que ser aleatorio, entonces se simula vía `rnorm()` al igual que $\varepsilon_{ij}$:

- $T_j \sim \mathcal{N}(0, \sigma^2_T)$  
- $\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2_\varepsilon)$

Se fija el valor de $\mu$.

Con estas asignaciones generamos un ANOVA:

```r
anova(y ~ trt)
```

- Luego se calcula $F$-stat  
- Se mira si se rechaza  
- Se supone que $H_0$ es falso para saber

La potencia de la prueba según $r$:




```{r}
r <- seq(1, 20, length.out = 100)
potencia <- 1 - exp(-0.3 * r)

plot(r, potencia, type = "l", lwd = 2, col = "orange",
     xlab = "r", ylab = "Potencia",
     main = "La potencia de la prueba según r")
abline(h = 0.8, lty = 2)
abline(v = 5.36, lty = 2)
text(8.2, 0.1, "r")
text(0.5, 0.85, "0.8")
text(8.2, 0.82, "1 - \\beta")
```



# Referencia

**Referencia Bibliográfica**

> Melo M., O. O., López P., L. A., & Melo M., S. E. (2007). _Diseño de Experimentos: Métodos y Aplicaciones_ (1a ed.). Pro-Oﬀset Editorial S.A.. Capítulo 5, pp. 189-207.
