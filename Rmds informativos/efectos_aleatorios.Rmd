---
title: "Modelos de efectos fijos vs aleatorios en el ANOVA a una vía"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

En el caso del ANOVA de una vía de clasificación:

$$
Y_{ij} = \mu + T_i + \varepsilon_{ij}
$$

- $\mu$: media general  
- $T_i$: efecto diferencial del tratamiento  
- $\varepsilon_{ij}$: error de la unidad observacional

Nosotros estimábamos a $T_i$ como si fuera un valor fijo, pero cuando tenemos efectos aleatorios:

$$
\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2_\varepsilon)
$$

Ahora $T_i$ va a ser aleatorio de individuo a individuo:

$$
T_j \sim \mathcal{N}(0, \sigma^2_T)
$$

Así tendremos dos efectos de varianza, entonces la idea se hace grande cuando vemos el diseño completamente al azar desde el punto de vista de los efectos aleatorios, ya no nos va a interesar evaluar la misma hipótesis.

**Hipótesis en efectos fijos:**

$$
H_0: \; T_1 = T_2 = \dots = T_K = 0
$$

Si no que:

**Hipótesis en efectos aleatorios:**

$$
H_0: \; \sigma^2_T = 0 \quad \text{(La varianza de los efectos aleatorios sea estadísticamente cero)}
$$

El cálculo es el mismo, solo que la hipótesis cambia.

> **Aclaración:**  
Que $T_k = 0 \Rightarrow \sigma^2_T = 0$, pero no al revés.  
Es decir, si $\sigma^2_T = 0$ implica que $T_k$ son iguales, pero no a cero.

**¿Cuándo decidimos usar cuál?**

En efectos fijos, los $T$ decimos que son parámetros fijos, que se espera que afecten a la variable dependiente de forma directa.  
En cambio, los efectos aleatorios me ayudan para explicar la variabilidad no explicada de las explicativas (punto de vista aleatorio).

**Ejemplo:**  
Si se tiene un estudio de diferentes fertilizantes y queremos evaluar el rendimiento en una cosecha, el investigador está pensando en elegir solo tres tipos de fertilizante.  
Para él, es un valor fijo dado que lo decidió bajo experiencia y quiere evaluar entre esos tres.  
→ **Efecto fijo**

Ahora, si en el mismo ejercicio se tiene un grupo más amplio de fertilizantes (20, 30, ..., X) y elijo aleatoriamente 3 por medio de un muestreo, entonces estoy pensando en efectos aleatorios.  
En ese caso, me interesa estimar la variabilidad del rendimiento de lo que estamos midiendo, causado por los diferentes tipos de fertilizantes.

Y en ese intento, la varianza asociada a los fertilizantes no se ve influenciada por la manera en que se eligen aleatoriamente los fertilizantes que se iban a usar en el estudio.

→ La diferencia de un modelo a otro reside en la concepción del experimento, pero en el contraste de las diferencias, o desde el punto de vista estadístico, es exactamente la misma tanto en efectos fijos como en efectos aleatorios.

Otra diferencia es que en E.F. a mí me interesa comparar niveles específicos, i.e., el fertilizante 1 vs. el 2, se comparan niveles específicos.

En cambio, en E.A. es controlar o evaluar qué tanto podrían cambiar la variabilidad en el rendimiento, o en la variable de respuesta por efecto del tratamiento.

→ Para contrastar el ejercicio se calcula el estadístico $F$ ya sea visto en E.F. o E.A.:

$$
F = \frac{CM_{Trat}}{CM_{Res}}
$$

Una cosa importante a tener en cuenta es que en el numerador de $F$ hay una combinación entre los $\sigma^2_T$ (variabilidad de tratamientos) y $\sigma^2_\varepsilon$ (variabilidad del error experimental).  
En cambio, en $CM_{Res}$ solo se tiene $\sigma^2_\varepsilon$.


→ Eso sería lo primero.

Ahora el ejercicio para calcular $CM_{Trat}$ para E.A. es el siguiente:

Suponemos que:

$$
SC_{Tot} = SC_{Trat} + SC_{Res}
$$

Sabemos que son chi-cuadrados, entonces:

$$
CM_{Trat} = \frac{SC_{Trat}}{K - 1} \sim \chi^2 \Rightarrow \mathbb{E}(CM_{Trat}) = \sigma^2_\varepsilon + r \cdot \sigma^2_T
$$

Donde $K$ es el número de tratamientos.  
Y para $CM_{Res}$:

$$
\mathbb{E}(CM_{Res}) = \sigma^2_\varepsilon
$$

Al final, va a pasar que la estadística $F$ bajo la hipótesis nula estará a tener distribución $F$, pero cuando no estoy bajo elsupuesto de la hipótesis nula, i.e., si $\sigma^2_T \neq 0$, el resultado de $F$ va a depender obligatoriamente de $\sigma^2_T$.

→ Las curvas características de operación (curvas OC) para el anterior escenario me dicen que a partir de la distribución exacta de la estadística $F$, cuando el $F$ no es centrado o no central, me dice que va a haber un cambio proporcional entre $F$ y $\sigma^2_T$.  
Entonces, lo que uno hace es una suerte de cociente:

$$
\rho = \frac{\sigma^2_T}{\sigma^2_\varepsilon}
$$

→ Para el ejercicio uno hace lo siguiente:

1. Simulación de cómo va a ser la potencia.  
   Hace el cálculo por el ANOVA:

   - Fijamos el número de tratamientos ($t$)  
   - Fijamos el número de réplicas ($r$)  
   - Fijamos $\sigma^2_\varepsilon$  
   - Fijamos $\beta$
   
Supongamos que ya tenemos claro el modelo:

$$
y_{ij} = \mu + T_j + \varepsilon_{ij}
$$

→ De $\sigma^2_\varepsilon$ y $\beta$ se puede recuperar $\sigma^2_T$.  
$T_j$ tiene que ser aleatorio, entonces se simula vía `rnorm()` al igual que $\varepsilon_{ij}$:

- $T_j \sim \mathcal{N}(0, \sigma^2_T)$  
- $\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2_\varepsilon)$

Se fija el valor de $\mu$.

Con estas asignaciones generamos un ANOVA:

```r
anova(y ~ trt)
```

- Luego se calcula $F$-stat  
- Se mira si se rechaza  
- Se supone que $H_0$ es falso para saber

La potencia de la prueba según $r$:




```{r}
r <- seq(1, 20, length.out = 100)
potencia <- 1 - exp(-0.3 * r)

plot(r, potencia, type = "l", lwd = 2, col = "orange",
     xlab = "r", ylab = "Potencia",
     main = "La potencia de la prueba según r")
abline(h = 0.8, lty = 2)
abline(v = 5.36, lty = 2)
text(8.2, 0.1, "r")
text(0.5, 0.85, "0.8")
text(8.2, 0.82, "1 - \\beta")
```



